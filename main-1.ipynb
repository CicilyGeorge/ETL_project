{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:47:03.292194Z",
     "start_time": "2020-11-30T15:46:43.532725Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abraham\\anaconda3\\envs\\python31\\lib\\site-packages\\ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Abraham\\anaconda3\\envs\\python31\\lib\\site-packages\\ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_num</th>\n",
       "      <th>num_figs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71709-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41391-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41405-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75978-1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75966-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   set_num  num_figs\n",
       "0  71709-1         3\n",
       "1  41391-1         2\n",
       "2  41405-1         5\n",
       "3  75978-1        17\n",
       "4  75966-1         4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####\n",
    "###\n",
    "##\n",
    "#    SYNOPSIS\n",
    "#\n",
    "#    As a small data analytics firm, our client approached us with an urgent project to collect information\n",
    "#    about this year’s LEGO sets. They are part of the manufacturing process of LEGO pieces; and want to do \n",
    "#    predictive data modelling to find out what materials will be more in demand next year, based on this\n",
    "#    year’s information, so that they can optimise their manufacturing process.\n",
    "#\n",
    "#    They have requested the information be put into database format so that it can be accessed in a way\n",
    "#    that they are already familiar with.\n",
    "#\n",
    "#    Based on the timeframe of 1 week, we have assigned the following team members to this project:\n",
    "#\n",
    "#    CONTRIBUTORS\n",
    "#    \n",
    "#    Sylvia Broadbent @github/Supasyl\n",
    "#    Cicily George @github/CicilyGeorge\n",
    "#    Daniel Sobral @github/D0SO\n",
    "#    John Bingley @github/JB-DA\n",
    "#\n",
    "#    Source and output can be found (with access) on https://github.com/Supasyl/ETL_project\n",
    "#\n",
    "##\n",
    "###\n",
    "#####\n",
    "\n",
    "\n",
    "### SETTINGS\n",
    "##\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import json\n",
    "\n",
    "viewHeaders = 'yes' #for displaying dataframes, yes/no\n",
    "headSize = 5 #rows to show if above line = yes\n",
    "\n",
    "\n",
    "### LOAD DATA FROM CSV\n",
    "##\n",
    "# Load pre-downloaded information\n",
    "df_colors = pd.read_csv( 'data_raw/colors.csv' )\n",
    "df_elements = pd.read_csv( 'data_raw/elements.csv' )\n",
    "df_inventories = pd.read_csv( 'data_raw/inventories.csv' )\n",
    "df_inventory_minifigs = pd.read_csv( 'data_raw/inventory_minifigs.csv' )\n",
    "df_inventory_parts = pd.read_csv( 'data_raw/inventory_parts.csv' )\n",
    "df_inventory_sets = pd.read_csv( 'data_raw/inventory_sets.csv' )\n",
    "df_minifigs = pd.read_csv( 'data_raw/minifigs.csv' )\n",
    "df_parts = pd.read_csv( 'data_raw/parts.csv' )\n",
    "df_sets = pd.read_csv( 'data_raw/sets.csv' )\n",
    "df_themes = pd.read_csv( 'data_raw/themes.csv' )\n",
    "\n",
    "\n",
    "### LOAD DATA FROM API\n",
    "##\n",
    "# Left as proof of code only. Results were stored to sets2020.json\n",
    "# API requires ' to be used in URL, converted to %27 for ease of use\n",
    "# Comment out code block and api_key before publishing\n",
    "\n",
    "# api_key = \"3-DLfb-T3ZA-qQLjW\"\n",
    "# url = \"https://brickset.com/api/v3.asmx/getSets?\"\n",
    "# query_url = f\"{url}apiKey={api_key}&userHash=&params={{ %27year%27:%272020%27, %27pageSize%27 : 900 }}\"\n",
    "\n",
    "# response = requests.get( query_url )\n",
    "\n",
    "# with open( 'api_sets_2020.json', 'w' ) as ii:\n",
    "#     json.dump( response.json(), ii )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CLEAN & JOIN DATA\n",
    "##\n",
    "# Looking at only data from 2020 sets\n",
    "df_clean_sets = df_sets.loc[ df_sets[ 'year' ] == 2020 ].copy()\n",
    "df_clean_sets.drop( 'year', axis = 1, inplace = True )\n",
    "\n",
    "\n",
    "# Inventories\n",
    "df_inventories = df_inventories.rename( columns = { 'id' : 'inventory_id' })\n",
    "df_temp = pd.merge( df_clean_sets, df_inventories, how = 'inner', on = 'set_num' )\n",
    "df_clean_inventories = df_temp[[ 'inventory_id', 'version', 'set_num' ]]\n",
    "\n",
    "# Inventory Sets\n",
    "df_temp = pd.merge( df_clean_sets, df_inventory_sets, how = 'inner', on = 'set_num' )\n",
    "df_clean_inventory_sets = df_temp[[ 'inventory_id', 'set_num', 'quantity' ]]\n",
    "\n",
    "# Themes\n",
    "df_themes = df_themes.rename( columns = { 'id' : 'theme_id', 'name' : 'theme_name' })\n",
    "df_temp = pd.merge( df_themes, df_clean_sets, how = 'inner', on = 'theme_id' )\n",
    "df_clean_themes = df_temp[[ 'theme_id', 'theme_name', 'parent_id' ]]\n",
    "df_clean_themes = df_clean_themes.drop_duplicates(keep='first')\n",
    "\n",
    "# Inventory Minifigs\n",
    "df_temp = pd.merge( df_clean_inventories, df_inventory_minifigs, how = 'inner', on = 'inventory_id' )\n",
    "df_clean_inventory_minifigs = df_temp[[ 'inventory_id', 'fig_num', 'quantity' ]]\n",
    "\n",
    "# Minifigs\n",
    "df_temp = pd.merge( df_clean_inventory_minifigs, df_minifigs, how = 'inner', on = 'fig_num' )\n",
    "df_clean_minifigs = df_temp[[ 'fig_num', 'name', 'num_parts' ]]\n",
    "df_clean_minifigs = df_clean_minifigs.drop_duplicates(keep='first')\n",
    "\n",
    "# Inventory Parts\n",
    "df_temp = pd.merge( df_inventory_parts, df_clean_inventories, how = 'inner', on = 'inventory_id' )\n",
    "df_clean_inventory_parts = df_temp[[ 'inventory_id', 'part_num', 'color_id', 'quantity', 'is_spare' ]]\n",
    "df_clean_inventory_parts[ 'is_spare' ] = df_clean_inventory_parts[ 'is_spare' ].map({ 't' : True, 'f' : False })\n",
    "df_clean_inventory_parts = df_clean_inventory_parts.drop_duplicates(keep='first')\n",
    "\n",
    "# Colours\n",
    "df_colors = df_colors.rename( columns = { 'id' : 'color_id' })\n",
    "df_temp = pd.merge( df_clean_inventory_parts, df_colors, how = 'inner', on = 'color_id' )\n",
    "df_clean_colors = df_temp[[ 'color_id', 'name', 'rgb', 'is_trans' ]]\n",
    "df_clean_colors[ 'is_trans' ] = df_clean_colors[ 'is_trans' ].map({ 't' : True, 'f' : False })\n",
    "df_clean_colors = df_clean_colors.drop_duplicates(keep='first')\n",
    "\n",
    "# Parts\n",
    "df_temp = pd.merge( df_clean_inventory_parts, df_parts, how = 'inner', on = 'part_num' )\n",
    "df_clean_parts = df_temp[[ 'part_num', 'name' ]] # , 'part_cat_id'\n",
    "df_clean_parts = df_clean_parts.drop_duplicates(keep='first')\n",
    "\n",
    "# Elements\n",
    "df_temp = pd.merge( df_clean_parts, df_elements, how = 'inner', on = 'part_num' )\n",
    "df_clean_elements = df_temp[[ 'element_id', 'part_num', 'color_id' ]]\n",
    "df_temp = pd.merge( df_clean_colors, df_clean_elements, how = 'inner', on = 'color_id' )\n",
    "df_clean_elements = df_temp[[ 'element_id', 'part_num', 'color_id' ]]\n",
    "df_clean_elements = df_clean_elements.drop_duplicates(keep='first')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# API Data Load\n",
    "with open( 'api_sets_2020.json', 'r' ) as jj: #open pre-made api results\n",
    "    json_d = json.load( jj )\n",
    "\n",
    "api_sets_2020 = pd.DataFrame( json_d[ 'sets' ]) #load to dataframe\n",
    "\n",
    "df_api_sets_2020 = api_sets_2020[[ 'number', 'rating', 'reviewCount' ]] #show only desired columns\n",
    "\n",
    "# Set API column number to match Lego ID number\n",
    "df_api_sets_2020 = df_api_sets_2020.rename( columns = { 'number' : 'set_num','reviewCount':'review_count' })\n",
    "df_api_sets_2020.set_num = df_api_sets_2020.set_num + '-1' #append -1 to column to match data in 'sets'\n",
    "\n",
    "# Merge API data with Sets Dataframe\n",
    "\n",
    "df_clean_sets = pd.merge( df_clean_sets, df_api_sets_2020, how = 'left', on = 'set_num' )\n",
    "df_clean_sets = df_clean_sets.drop_duplicates(keep='first')\n",
    "df_clean_sets = df_clean_sets.drop_duplicates(['set_num'],keep='first')\n",
    "\n",
    "\n",
    "### PUSH TO DATABASE\n",
    "##\n",
    "# Connect to database\n",
    "# connection_string = \"postgres:postgres@localhost:5432/Lego_db\"\n",
    "# engine = create_engine(f'postgresql://{connection_string}')\n",
    "engine = create_engine(f\"postgresql://postgres:postgres@localhost:5432/Lego_db\")\n",
    "engine.begin()\n",
    "con = engine.connect()\n",
    "\n",
    "# Check table names\n",
    "engine.table_names()\n",
    "\n",
    "# Load dataframes into database\n",
    "df_clean_themes.to_sql( name = 'themes', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_sets.to_sql( name = 'sets', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_inventories.to_sql( name = 'inventories', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_inventory_sets.to_sql( name = 'inventory_sets', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_minifigs.to_sql( name = 'minifigs', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_inventory_minifigs.to_sql( name = 'inventory_minifigs', con = engine, if_exists = 'append', index = False )\n",
    "# df_clean_part_categories.to_sql( name = 'part_categories', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_colors.to_sql( name = 'colors', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_parts.to_sql( name = 'parts', con = engine, if_exists = 'append', index = False )\n",
    "# df_clean_part_relationships.to_sql( name = 'part_relationships', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_elements.to_sql( name = 'elements', con = engine, if_exists = 'append', index = False )\n",
    "df_clean_inventory_parts.to_sql( name = 'inventory_parts', con = engine, if_exists = 'append', index = True )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Query records in database for test purpose\n",
    "# Query for total no.of pieces in a set\n",
    "query = \"select a.set_num, sum(b.quantity) as no_of_pieces\\\n",
    "    from inventories as a, inventory_parts as b\\\n",
    "    where a.inventory_id = b.inventory_id\\\n",
    "    group by a.set_num;\"\n",
    "pd.read_sql_query(query, con=engine).head()\n",
    "\n",
    "\n",
    "# Query for total no.of minifigs in a set\n",
    "query = \"select a.set_num, sum(b.quantity) as num_figs\\\n",
    "    from inventories as a, inventory_minifigs as b\\\n",
    "    where a.inventory_id = b.inventory_id\\\n",
    "    group by a.set_num;\"\n",
    "pd.read_sql_query(query, con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:45:51.777998Z",
     "start_time": "2020-11-30T15:45:49.674Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### VIEW DATA (Validation Purposes Only)\n",
    "##\n",
    "# Uses value under 'SETTINGS' at top of file\n",
    "if viewHeaders == 'yes':\n",
    "    \n",
    "    display( df_clean_colors \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Colours' ))\n",
    "    \n",
    "    display( df_clean_elements \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Elements' ))\n",
    "    \n",
    "    display( df_clean_inventories \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Inventories' ))\n",
    "    \n",
    "    display( df_clean_inventory_minifigs \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Inventory Mini-figures' ))\n",
    "    \n",
    "    display( df_clean_inventory_parts \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Inventory Parts' ))\n",
    "    \n",
    "    display( df_clean_inventory_sets \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Inventory Sets' ))\n",
    "    \n",
    "    display( df_clean_minifigs \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Mini-figures' ))\n",
    "    \n",
    "    display( df_clean_part_categories \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Part Categories' ))\n",
    "    \n",
    "    display( df_clean_part_relationships \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Part Relationships' ))\n",
    "    \n",
    "    display( df_clean_parts \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Parts' ))\n",
    "    \n",
    "    display( df_clean_sets \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Sets' ))\n",
    "    \n",
    "    display( df_clean_themes \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Themes' ))\n",
    "    # END IF\n",
    "\n",
    "\n",
    "### LEGACY CODE\n",
    "##\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "40",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
