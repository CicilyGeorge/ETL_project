{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T12:46:27.286308Z",
     "start_time": "2020-11-29T12:46:21.751393Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "###\n",
    "##\n",
    "#    SYNOPSIS\n",
    "#\n",
    "#    As a small data analytics firm, our client approached us with an urgent project to collect information\n",
    "#    about this year’s LEGO sets. They are part of the manufacturing process of LEGO pieces; and want to do \n",
    "#    predictive data modelling to find out what materials will be more in demand next year, based on this\n",
    "#    year’s information, so that they can optimise their manufacturing process.\n",
    "#\n",
    "#    They have requested the information be put into database format so that it can be accessed in a way\n",
    "#    that they are already familiar with.\n",
    "#\n",
    "#    Based on the timeframe of 1 week, we have assigned the following team members to this project:\n",
    "#\n",
    "#    CONTRIBUTORS\n",
    "#    \n",
    "#    Sylvia Broadbent @github/Supasyl\n",
    "#    Cicily George @github/CicilyGeorge\n",
    "#    Daniel Sobral @github/D0SO\n",
    "#    John Bingley @github/JB-DA\n",
    "#\n",
    "#    Source and output can be found (with access) on https://github.com/Supasyl/ETL_project\n",
    "#\n",
    "##\n",
    "###\n",
    "#####\n",
    "\n",
    "\n",
    "### SETTINGS\n",
    "##\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "### LOAD DATA FROM CSV\n",
    "##\n",
    "# Load pre-downloaded information\n",
    "df_colors = pd.read_csv( 'data_raw/colors.csv' )\n",
    "df_elements = pd.read_csv( 'data_raw/elements.csv' )\n",
    "df_inventories = pd.read_csv( 'data_raw/inventories.csv' )\n",
    "df_inventory_minifigs = pd.read_csv( 'data_raw/inventory_minifigs.csv' )\n",
    "df_inventory_parts = pd.read_csv( 'data_raw/inventory_parts.csv' )\n",
    "df_inventory_sets = pd.read_csv( 'data_raw/inventory_sets.csv' )\n",
    "df_minifigs = pd.read_csv( 'data_raw/minifigs.csv' )\n",
    "df_part_categories = pd.read_csv( 'data_raw/part_categories.csv' )\n",
    "df_part_relationships = pd.read_csv( 'data_raw/part_relationships.csv' )\n",
    "df_parts = pd.read_csv( 'data_raw/parts.csv' )\n",
    "df_sets = pd.read_csv( 'data_raw/sets.csv' )\n",
    "df_themes = pd.read_csv( 'data_raw/themes.csv' )\n",
    "\n",
    "\n",
    "### LOAD DATA FROM API\n",
    "##\n",
    "# Left as proof of code only. Results were stored to sets2020.json\n",
    "# API requires ' to be used in URL, converted to %27 for ease of use\n",
    "# Comment out code block and api_key before publishing\n",
    "api_key = \"3-DLfb-T3ZA-qQLjW\"\n",
    "url = \"https://brickset.com/api/v3.asmx/getSets?\"\n",
    "query_url = f\"{url}apiKey={api_key}&userHash=&params={{ %27year%27:%272020%27, %27pageSize%27 : 900 }}\"\n",
    "\n",
    "response = requests.get(query_url)\n",
    "\n",
    "with open('sets2020.json', 'w') as x:\n",
    "    json.dump(response.json(), x)\n",
    "\n",
    "\n",
    "### CLEAN & JOIN DATA\n",
    "##\n",
    "# Looking at only data from 2020 sets\n",
    "df_clean_sets = df_sets.loc[ df_sets[ 'year' ] == 2020 ].copy()\n",
    "df_clean_sets.drop( 'year', axis = 1, inplace = True )\n",
    "\n",
    "# Inventories\n",
    "df_inventories = df_inventories.rename( columns = { 'id' : 'inventory_id' })\n",
    "df_temp = pd.merge( df_clean_sets, df_inventories, how = 'inner', on = 'set_num' )\n",
    "df_clean_inventories = df_temp[[ 'inventory_id', 'version', 'set_num' ]]\n",
    "\n",
    "# Inventory Sets\n",
    "df_temp = pd.merge( df_clean_sets, df_inventory_sets, how = 'inner', on = 'set_num' )\n",
    "df_clean_inventory_sets = df_temp[[ 'inventory_id', 'set_num', 'quantity' ]]\n",
    "\n",
    "# Themes\n",
    "df_themes = df_themes.rename( columns = { 'id' : 'theme_id', 'name' : 'theme_name' })\n",
    "df_temp = pd.merge( df_themes, df_clean_sets, how = 'inner', on = 'theme_id' )\n",
    "df_clean_themes = df_temp[[ 'theme_id', 'theme_name', 'parent_id' ]]\n",
    "\n",
    "# Inventory Minifigs\n",
    "df_temp = pd.merge( df_clean_inventories, df_inventory_minifigs, how = 'inner', on = 'inventory_id' )\n",
    "df_clean_inventory_minifigs = df_temp[[ 'inventory_id', 'fig_num', 'quantity' ]]\n",
    "\n",
    "# Minifigs\n",
    "df_temp = pd.merge( df_clean_inventory_minifigs, df_minifigs, how = 'inner', on = 'fig_num' )\n",
    "df_clean_minifigs = df_temp[[ 'fig_num', 'name', 'num_parts' ]]\n",
    "\n",
    "# Inventory Parts\n",
    "df_temp = pd.merge( df_inventory_parts, df_clean_inventories, how = 'inner', on = 'inventory_id' )\n",
    "df_clean_inventory_parts = df_temp[[ 'inventory_id', 'part_num', 'color_id', 'quantity', 'is_spare' ]]\n",
    "df_clean_inventory_parts[ 'is_spare' ] = df_clean_inventory_parts[ 'is_spare' ].map({ 't' : True, 'f' : False })\n",
    "\n",
    "# Colours\n",
    "df_colors = df_colors.rename( columns = { 'id' : 'color_id' })\n",
    "df_temp = pd.merge( df_clean_inventory_parts, df_colors, how = 'inner', on = 'color_id' )\n",
    "df_clean_colors = df_temp[[ 'color_id', 'name', 'rgb', 'is_trans' ]]\n",
    "df_clean_colors[ 'is_trans' ] = df_clean_colors[ 'is_trans' ].map({ 't' : True, 'f' : False })\n",
    "\n",
    "# Parts\n",
    "df_temp = pd.merge( df_clean_inventory_parts, df_parts, how = 'inner', on = 'part_num' )\n",
    "df_clean_parts = df_temp[[ 'part_num', 'name', 'part_cat_id' ]]\n",
    "\n",
    "# Elements\n",
    "df_temp = pd.merge( df_clean_parts, df_elements, how = 'inner', on = 'part_num' )\n",
    "df_clean_elements = df_temp[[ 'element_id', 'part_num', 'color_id' ]]\n",
    "\n",
    "# Part Categories\n",
    "df_part_categories = df_part_categories.rename( columns = { 'id' : 'part_cat_id', 'name' : 'part_name' })\n",
    "df_temp = pd.merge( df_clean_parts, df_part_categories, how = 'inner', on = 'part_cat_id' )\n",
    "df_clean_part_categories = df_temp[[ 'part_cat_id', 'part_name' ]]\n",
    "\n",
    "# Part Relationships\n",
    "df_part_relationships = df_part_relationships.rename( columns = { 'child_part_num' : 'part_num' })\n",
    "df_temp = pd.merge( df_clean_parts, df_part_relationships, how = 'inner', on = 'part_num' )\n",
    "df_clean_part_relationships = df_temp[[ 'rel_type', 'part_num', 'parent_part_num' ]]\n",
    "\n",
    "\n",
    "# ### PUSH TO DATABASE\n",
    "# ##\n",
    "# Connect to database\n",
    "connection_string = \"postgres:postgres@localhost:5432/Lego_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')\n",
    "\n",
    "# Get table names\n",
    "engine.table_names()\n",
    "\n",
    "# Load dataframes into database\n",
    "df_clean_colors.tosql( name = 'colors', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_elements.tosql( name = 'elements', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_inventories.tosql( name = 'inventories', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_inventory_minifigs.tosql( name = 'inventory_minifigs', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_inventory_parts.tosql( name = 'inventory_parts', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_inventory_sets.tosql( name = 'inventory_sets', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_minifigs.tosql( name = 'minifigs', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_part_categories.tosql( name = 'part_categories', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_part_relationships.tosql( name = 'part_relationships', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_parts.tosql( name = 'parts', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_sets.tosql( name = 'sets', con = engine, if_exists = 'append', index = True )\n",
    "df_clean_themes.tosql( name = 'themes', con = engine, if_exists = 'append', index = True )\n",
    "\n",
    "# Query records in database\n",
    "pd.read_sql_query('select * from sets', con=engine).head()\n",
    "\n",
    "\n",
    "### VIEW DATA (Validation Purposes Only)\n",
    "##\n",
    "# Set viewHeaders to yes/no to display tables, used for validation purposes only\n",
    "viewHeaders = 'yes'\n",
    "headSize = 5\n",
    "\n",
    "if viewHeaders == 'yes':\n",
    "    \n",
    "    display( df_clean_colors \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Colour value and names' ))\n",
    "    \n",
    "    display( df_clean_elements \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Parts and colour combinations' ))\n",
    "    \n",
    "    display( df_clean_inventories \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Rebrickable ID and Lego ID' ))\n",
    "    \n",
    "    display( df_clean_inventory_minifigs \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Mini-figures in sets using Rebrickable ID' ))\n",
    "    \n",
    "    display( df_clean_inventory_parts \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Parts in sets using Rebrickable ID' ))\n",
    "    \n",
    "    display( df_clean_inventory_sets \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Lego sets' ))\n",
    "    \n",
    "    display( df_clean_minifigs \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Mini-figures and their ID' ))\n",
    "    \n",
    "    display( df_clean_part_categories \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Type of brick' ))\n",
    "    \n",
    "    display( df_clean_part_relationships \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Parts and parents if applicable' ))\n",
    "    \n",
    "    display( df_clean_parts \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Parts and descriptions' ))\n",
    "    \n",
    "    display( df_clean_sets \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Sets using Lego ID' ))\n",
    "    \n",
    "    display( df_clean_themes \\\n",
    "        .head( headSize ) \\\n",
    "        .style.set_caption( 'Table: Theme names and their Rebrickable ID' ))\n",
    "    # END IF\n",
    "\n",
    "\n",
    "### LEGACY CODE\n",
    "##\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": "40",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
